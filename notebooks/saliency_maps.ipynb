{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_model\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     load_config,\n\u001b[0;32m     15\u001b[0m     load_model,\n\u001b[0;32m     16\u001b[0m     get_metric_tracker,\n\u001b[0;32m     17\u001b[0m     load_data_handler,\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32md:\\Studia\\Neural-Deep-Retina\\notebooks\\..\\src\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_training_arguments, get_testing_arguments\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "File \u001b[1;32md:\\Studia\\Neural-Deep-Retina\\notebooks\\..\\src\\utils\\load_config.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Config,\n\u001b[0;32m      4\u001b[0m     DataConfig,\n\u001b[0;32m      5\u001b[0m     EncoderConfig,\n\u001b[0;32m      6\u001b[0m     PredictorConfig,\n\u001b[0;32m      7\u001b[0m     TrainingConfig,\n\u001b[0;32m      8\u001b[0m     TestingConfig,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_config\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Config:\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load config from yaml file.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m        Config: config object\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_models'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.utils.logger import get_logger\n",
    "from src.utils.training_utils import test_model\n",
    "from src.utils import (\n",
    "    load_config,\n",
    "    load_model,\n",
    "    get_metric_tracker,\n",
    "    load_data_handler,\n",
    ")\n",
    "from src.visualize.visualize_dataset import visualize_outputs_and_targets\n",
    "\n",
    "\n",
    "\n",
    "results_dir = Path(\"og_encoder_exp_1\")\n",
    "\n",
    "# Create path object to results directory\n",
    "results_dir_path = Path(\"..\") / \"results\" / results_dir\n",
    "# Load config from the results directory\n",
    "config_path = results_dir_path / \"config.yaml\"\n",
    "\n",
    "config = load_config(config_path)\n",
    "\n",
    "logger = get_logger(\n",
    "    log_to_file=config.testing.save_logs,\n",
    "    log_file=results_dir_path / \"test_logs.log\",\n",
    ")\n",
    "\n",
    "logger.info(\"Preparing to test model...\")\n",
    "logger.info(f\"Using config file: {config_path}\")\n",
    "weights_path = results_dir_path / \"models\" / config.testing.weights\n",
    "logger.info(f\"Using model: {weights_path}\")\n",
    "\n",
    "# load the model\n",
    "logger.info(\"Loading model...\")\n",
    "model = load_model(config)\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "test_dataset = load_data_handler(\n",
    "    config.data,\n",
    "    results_dir=results_dir_path,\n",
    "    is_train=False,\n",
    "    y_scaler=StandardScaler(),\n",
    "    use_saved_scaler=True,\n",
    ")\n",
    "\n",
    "# Get sample data to check dimensions\n",
    "X, y = test_dataset[0]\n",
    "logger.info(f\"Input data point shape: {X.shape}\")\n",
    "logger.info(f\"Target data point shape: {y.shape}\")\n",
    "\n",
    "TORCH_SEED = 12\n",
    "logger.info(f\"Manually set PyTorch seed: {TORCH_SEED}\")\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Define training parameters\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE_NAME = torch.cuda.get_device_name(0) if DEVICE == \"cuda\" else \"CPU\"\n",
    "PIN_MEMORY = False  # torch.cuda.is_available()\n",
    "NUM_WORKERS = 0  # if torch.cuda.is_available() else 0\n",
    "BATCH_SIZE = config.testing.batch_size\n",
    "\n",
    "# read _id from .txt file\n",
    "with open(results_dir_path / \"id.txt\", \"r\") as f:\n",
    "    uuid = f.readline().strip()\n",
    "print(uuid)\n",
    "\n",
    "# Define data loaders\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create metric tracker\n",
    "metrics_tracker = get_metric_tracker(config.testing.metrics)\n",
    "metrics_tracker.to(DEVICE)\n",
    "\n",
    "# Set the path for saving predictions\n",
    "predictions_dir = results_dir_path / \"testset_predictions\"\n",
    "# Set the path for saving plots\n",
    "plots_dir = results_dir_path / \"plots\"\n",
    "\n",
    "# Test the model\n",
    "logger.info(f\"Testing on {DEVICE} using device: {DEVICE_NAME}\")\n",
    "model.to(DEVICE)\n",
    "start_testing_time = time()\n",
    "\n",
    "test_loss, metrics_dict = test_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    device=DEVICE,\n",
    "    tracker=metrics_tracker,\n",
    "    save_outputs_and_targets=True,\n",
    "    save_dir=predictions_dir,\n",
    ")\n",
    "\n",
    "outputs = pd.read_csv(predictions_dir / \"outputs.csv\")\n",
    "targets = pd.read_csv(predictions_dir / \"targets.csv\")\n",
    "\n",
    "total_time = time() - start_testing_time\n",
    "logger.info(f\"Test loss: {test_loss:.4f}\")\n",
    "logger.info(f\"Total testing time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "df_results = pd.DataFrame(metrics_dict)\n",
    "logger.info(\n",
    "    \"Results {}\".format(df_results.to_string().replace(\"\\n\", \"\\n\\t\\t\\t\\t\\t\"))\n",
    ")\n",
    "\n",
    "# Save results to a csv file\n",
    "df_results.to_csv(results_dir_path / \"test_results.csv\", index=False)\n",
    "logger.info(f\"Results saved to {results_dir_path / 'test_results.csv'}\")\n",
    "\n",
    "# Plot outputs and targets\n",
    "fig = visualize_outputs_and_targets(\n",
    "    predictions_dir,\n",
    "    plots_dir,\n",
    "    file_name=\"test_outputs_and_targets.png\",\n",
    "    is_train=False,\n",
    "    return_fig=True,\n",
    ")\n",
    "\n",
    "logger.info(f\"Outputs and targets visualization saved to {predictions_dir}\")\n",
    "\n",
    "if config.testing.run_on_train_data:\n",
    "    logger.info(\"Testing on the training data...\")\n",
    "\n",
    "    train_dataset = load_data_handler(\n",
    "        config.data,\n",
    "        results_dir=results_dir_path,\n",
    "        is_train=True,\n",
    "        y_scaler=StandardScaler(),\n",
    "        use_saved_scaler=True,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "    # Set the path for saving predictions\n",
    "    predictions_dir = results_dir_path / \"trainset_predictions\"\n",
    "    # Create metric tracker\n",
    "    metrics_tracker = get_metric_tracker(config.testing.metrics)\n",
    "    metrics_tracker.to(DEVICE)\n",
    "\n",
    "    # Test the model\n",
    "    logger.info(\"Testing model on the training data...\")\n",
    "    start_testing_time = time()\n",
    "\n",
    "    test_loss, metrics_dict = test_model(\n",
    "        model=model,\n",
    "        test_loader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        device=DEVICE,\n",
    "        tracker=metrics_tracker,\n",
    "        save_outputs_and_targets=True,\n",
    "        save_dir=predictions_dir,\n",
    "    )\n",
    "\n",
    "    outputs = pd.read_csv(predictions_dir / \"outputs.csv\")\n",
    "    targets = pd.read_csv(predictions_dir / \"targets.csv\")\n",
    "\n",
    "    total_time = time() - start_testing_time\n",
    "    logger.info(f\"Test loss: {test_loss:.4f}\")\n",
    "    logger.info(f\"Total testing time: {total_time:.2f} seconds\")\n",
    "\n",
    "    # Create a DataFrame from the metrics dictionary\n",
    "    df_results = pd.DataFrame(metrics_dict)\n",
    "    logger.info(\n",
    "        \"Results {}\".format(df_results.to_string().replace(\"\\n\", \"\\n\\t\\t\\t\\t\\t\"))\n",
    "    )\n",
    "\n",
    "    # Save results to a csv file\n",
    "    df_results.to_csv(results_dir_path / \"test_traindata_results.csv\", index=False)\n",
    "    logger.info(\n",
    "        f\"Results saved to {results_dir_path / 'test_traindata_results.csv'}\"\n",
    "    )\n",
    "    # Plot outputs and targets\n",
    "    fig = visualize_outputs_and_targets(\n",
    "        predictions_dir,\n",
    "        plots_dir,\n",
    "        file_name=\"train_outputs_and_targets.png\",\n",
    "        is_train=True,\n",
    "        return_fig=True,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
